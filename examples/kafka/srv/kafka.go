// Code generated by dol build. Only Generate by tools if not existed.
// source: kafka.go

package srv

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"kafka/model"
	"time"

	"github.com/2637309949/dolphin/packages/gin"
	"github.com/2637309949/dolphin/packages/logrus"
	"github.com/2637309949/dolphin/packages/xormplus/xorm"
	"github.com/go-errors/errors"
	kafka "github.com/segmentio/kafka-go"
)

var kafkaConn *kafka.Conn

func init() {
	var err error
	topic, partition := "score-topic", 0
	kafkaConn, err = kafka.DialLeader(context.Background(), "tcp", "172.16.10.191:9092", topic, partition)
	if err != nil {
		logrus.Error("failed to dial leader:", err)
	} else {
		kafkaConn.SetWriteDeadline(time.Now().Add(10 * time.Second))
		kafkaConn.SetReadDeadline(time.Now().Add(10 * time.Second))
	}
}

// KafkaProducer defined srv
func KafkaProducer(ctx *gin.Context, db *xorm.Engine, params model.KafkaInfo) (interface{}, error) {
	kpStr, err := json.Marshal(&params)
	if err != nil {
		logrus.Error("failed to marshal:", err)
		return nil, err
	}
	n, err := kafkaConn.WriteMessages(kafka.Message{Value: kpStr})
	if err != nil {
		logrus.Error("failed to write messages:", err)
		return nil, err
	}
	return n, nil
}

// KafkaConsumer defined srv
func KafkaConsumer(ctx *gin.Context, db *xorm.Engine, params map[string]interface{}) (interface{}, error) {
	defer func() {
		if err := recover(); err != nil {
			goErr := errors.Wrap(err.(error), 3)
			fmt.Print(string(goErr.Stack()))
		}
	}()
	batch := kafkaConn.ReadBatch(10e3, 1e6) // fetch 10KB min, 1MB max
	defer batch.Close()
	var buffer bytes.Buffer
	var items []model.KafkaInfo
	for {
		b := make([]byte, 10e3) // 10KB max per message
		n, err := batch.Read(b)
		buffer.Write(b[:n])
		if err != nil {
			break
		}
		if bte := buffer.Bytes(); len(bte) > 0 {
			value := model.KafkaInfo{}
			if err := json.Unmarshal(bte, &value); err != nil {
				logrus.Error("failed to unmarshal:", err)
				return nil, err
			}
			items = append(items, value)
		}
	}
	return items, nil
}
